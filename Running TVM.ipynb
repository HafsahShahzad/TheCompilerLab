{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28ad70d-7056-4b41-96bc-1a6576f6fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax import Expr, Function\n",
    "from tvm.ir import IRModule\n",
    "from tvm.script import relax as R\n",
    "import numpy as np\n",
    "import onnx\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f4c331-f0da-47bf-8756-4ceddb50d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module has no function 'main'\n",
      "Trying to call 'add_one' instead\n",
      "Result from add_one: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "@R.function\n",
    "def add_one(x: R.Tensor((10,), \"float32\")) -> R.Tensor((10,), \"float32\"):\n",
    "    with R.dataflow():\n",
    "        y = R.add(x, R.const(1, \"float32\"))\n",
    "        R.output(y)\n",
    "    return y\n",
    "\n",
    "mod = IRModule({\"main\": add_one})\n",
    "\n",
    "target = \"llvm\"\n",
    "ex = relax.build(mod, target)\n",
    "\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "# Try to call 'main'\n",
    "try:\n",
    "    out = vm[\"main\"](tvm.nd.array(np.arange(10, dtype=\"float32\")))\n",
    "    print(\"Result from main:\", out.numpy())\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "    print(\"Trying to call 'add_one' instead\")\n",
    "\n",
    "    # Try 'add_one'\n",
    "    try:\n",
    "        out = vm[\"add_one\"](tvm.nd.array(np.arange(10, dtype=\"float32\")))\n",
    "        print(\"Result from add_one:\", out.numpy())\n",
    "    except AttributeError as e2:\n",
    "        print(e2)\n",
    "        print(\"Function not found in VM module.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fbe90a-23ff-44dd-8037-628b4f283320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.export import export\n",
    "from torchvision.models.resnet import ResNet18_Weights, resnet18\n",
    "\n",
    "torch_model = resnet18(weights=ResNet18_Weights.DEFAULT).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d69a8b4-90d3-4f3a-a484-ba15a61ae80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #A2F\">@I</span><span style=\"color: #A2F; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #00F; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #A2F\">@R</span><span style=\"color: #A2F; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">main</span>(x: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_fc_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1000</span>, <span style=\"color: #008000\">512</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_fc_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1000</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">-&gt;</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        R<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">112</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(x, p_conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">112</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv, p_bn1_weight, p_bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv2: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">112</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv1[<span style=\"color: #008000\">0</span>]\n",
       "            lv3: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">112</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv2)\n",
       "            lv4: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>max_pool2d(lv3, pool_size<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>], strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], ceil_mode<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">False</span>, count_include_pad<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">False</span>, layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>)\n",
       "            lv5: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv4, p_getattr_l__self___layer1___0___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv6: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv5, p_getattr_l__self___layer1___0___bn1_weight, p_getattr_l__self___layer1___0___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv7: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv6[<span style=\"color: #008000\">0</span>]\n",
       "            lv8: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv7)\n",
       "            lv9: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv8, p_getattr_l__self___layer1___0___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv10: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv9, p_getattr_l__self___layer1___0___bn2_weight, p_getattr_l__self___layer1___0___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">5</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv11: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv10[<span style=\"color: #008000\">0</span>]\n",
       "            lv12: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv11, lv4)\n",
       "            lv13: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv12)\n",
       "            lv14: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv13, p_getattr_l__self___layer1___1___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv15: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv14, p_getattr_l__self___layer1___1___bn1_weight, p_getattr_l__self___layer1___1___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">6</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">7</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv16: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv15[<span style=\"color: #008000\">0</span>]\n",
       "            lv17: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv16)\n",
       "            lv18: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv17, p_getattr_l__self___layer1___1___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv19: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv18, p_getattr_l__self___layer1___1___bn2_weight, p_getattr_l__self___layer1___1___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">8</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">9</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv20: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv19[<span style=\"color: #008000\">0</span>]\n",
       "            lv21: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv20, lv13)\n",
       "            lv22: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv21)\n",
       "            lv23: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv22, p_getattr_l__self___layer2___0___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv24: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv23, p_getattr_l__self___layer2___0___bn1_weight, p_getattr_l__self___layer2___0___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">10</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">11</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv25: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv24[<span style=\"color: #008000\">0</span>]\n",
       "            lv26: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv25)\n",
       "            lv27: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv26, p_getattr_l__self___layer2___0___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv28: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv27, p_getattr_l__self___layer2___0___bn2_weight, p_getattr_l__self___layer2___0___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">12</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">13</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv29: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv28[<span style=\"color: #008000\">0</span>]\n",
       "            lv30: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv22, p_getattr_l__self___layer2___0___downsample_0_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv31: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv30, p_getattr_l__self___layer2___0___downsample_1_weight, p_getattr_l__self___layer2___0___downsample_1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">14</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">15</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv32: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv31[<span style=\"color: #008000\">0</span>]\n",
       "            lv33: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv29, lv32)\n",
       "            lv34: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv33)\n",
       "            lv35: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv34, p_getattr_l__self___layer2___1___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv36: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv35, p_getattr_l__self___layer2___1___bn1_weight, p_getattr_l__self___layer2___1___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">16</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">17</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv37: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv36[<span style=\"color: #008000\">0</span>]\n",
       "            lv38: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv37)\n",
       "            lv39: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv38, p_getattr_l__self___layer2___1___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv40: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv39, p_getattr_l__self___layer2___1___bn2_weight, p_getattr_l__self___layer2___1___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">18</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">19</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv41: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv40[<span style=\"color: #008000\">0</span>]\n",
       "            lv42: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv41, lv34)\n",
       "            lv43: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv42)\n",
       "            lv44: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv43, p_getattr_l__self___layer3___0___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv45: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv44, p_getattr_l__self___layer3___0___bn1_weight, p_getattr_l__self___layer3___0___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">20</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">21</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv46: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv45[<span style=\"color: #008000\">0</span>]\n",
       "            lv47: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv46)\n",
       "            lv48: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv47, p_getattr_l__self___layer3___0___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv49: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv48, p_getattr_l__self___layer3___0___bn2_weight, p_getattr_l__self___layer3___0___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">22</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">23</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv50: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv49[<span style=\"color: #008000\">0</span>]\n",
       "            lv51: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv43, p_getattr_l__self___layer3___0___downsample_0_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv52: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv51, p_getattr_l__self___layer3___0___downsample_1_weight, p_getattr_l__self___layer3___0___downsample_1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">24</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">25</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv53: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv52[<span style=\"color: #008000\">0</span>]\n",
       "            lv54: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv50, lv53)\n",
       "            lv55: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv54)\n",
       "            lv56: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv55, p_getattr_l__self___layer3___1___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv57: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv56, p_getattr_l__self___layer3___1___bn1_weight, p_getattr_l__self___layer3___1___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">26</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">27</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv58: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv57[<span style=\"color: #008000\">0</span>]\n",
       "            lv59: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv58)\n",
       "            lv60: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv59, p_getattr_l__self___layer3___1___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv61: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv60, p_getattr_l__self___layer3___1___bn2_weight, p_getattr_l__self___layer3___1___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">28</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">29</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv62: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv61[<span style=\"color: #008000\">0</span>]\n",
       "            lv63: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv62, lv55)\n",
       "            lv64: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv63)\n",
       "            lv65: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv64, p_getattr_l__self___layer4___0___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv66: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv65, p_getattr_l__self___layer4___0___bn1_weight, p_getattr_l__self___layer4___0___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">30</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">31</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv67: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv66[<span style=\"color: #008000\">0</span>]\n",
       "            lv68: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv67)\n",
       "            lv69: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv68, p_getattr_l__self___layer4___0___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv70: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv69, p_getattr_l__self___layer4___0___bn2_weight, p_getattr_l__self___layer4___0___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">32</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">33</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv71: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv70[<span style=\"color: #008000\">0</span>]\n",
       "            lv72: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv64, p_getattr_l__self___layer4___0___downsample_0_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv73: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv72, p_getattr_l__self___layer4___0___downsample_1_weight, p_getattr_l__self___layer4___0___downsample_1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">34</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">35</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv74: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv73[<span style=\"color: #008000\">0</span>]\n",
       "            lv75: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv71, lv74)\n",
       "            lv76: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv75)\n",
       "            lv77: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv76, p_getattr_l__self___layer4___1___conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv78: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv77, p_getattr_l__self___layer4___1___bn1_weight, p_getattr_l__self___layer4___1___bn1_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">36</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">37</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv79: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv78[<span style=\"color: #008000\">0</span>]\n",
       "            lv80: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv79)\n",
       "            lv81: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv80, p_getattr_l__self___layer4___1___conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv82: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>batch_norm(lv81, p_getattr_l__self___layer4___1___bn2_weight, p_getattr_l__self___layer4___1___bn2_bias, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">38</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">39</span>], axis<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, epsilon<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1.0000000000000001e-05</span>, center<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, scale<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, momentum<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">0.10000000000000001</span>, training<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "            lv83: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> lv82[<span style=\"color: #008000\">0</span>]\n",
       "            lv84: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv83, lv76)\n",
       "            lv85: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(lv84)\n",
       "            lv86: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>adaptive_avg_pool2d(lv85, output_size<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>)\n",
       "            lv87: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>reshape(lv86, R<span style=\"color: #A2F; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>]))\n",
       "            lv88: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>permute_dims(p_fc_weight, axes<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv89: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>matmul(lv87, lv88, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv90: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv89, p_fc_bias)\n",
       "            gv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> (lv90,)\n",
       "            R<span style=\"color: #A2F; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend.torch import from_exported_program\n",
    "\n",
    "# Give an example argument to torch.export\n",
    "example_args = (torch.randn(1, 3, 224, 224, dtype=torch.float32),)\n",
    "\n",
    "# Skip running in CI environment\n",
    "IS_IN_CI = os.getenv(\"CI\", \"\") == \"true\"\n",
    "\n",
    "if not IS_IN_CI:\n",
    "    # Convert the model to IRModule\n",
    "    with torch.no_grad():\n",
    "        exported_program = export(torch_model, example_args)\n",
    "        mod = from_exported_program(exported_program, keep_params_as_input=True)\n",
    "\n",
    "    mod, params = relax.frontend.detach_params(mod)\n",
    "    mod.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2419975f-fd27-4341-b97d-8c833d3afc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.3-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/hafsahshahzad/tvm_env/lib/python3.12/site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in /Users/hafsahshahzad/tvm_env/lib/python3.12/site-packages (from xgboost) (1.16.1)\n",
      "Downloading xgboost-3.0.3-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.3\n",
      "2025-08-06 13:59:17 [INFO] Logging directory: tuning_logs/logs\n",
      "2025-08-06 13:59:17 [INFO] LocalBuilder: max_workers = 14\n",
      "2025-08-06 13:59:17 [INFO] LocalRunner: max_workers = 1\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #0: \"reshape\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #1: \"fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #2: \"fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #3: \"fused_matmul_add13\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #4: \"adaptive_avg_pool2d\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #5: \"fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #6: \"fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #7: \"fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #8: \"fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #9: \"fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #10: \"fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #11: \"fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:59:18] /Users/hafsahshahzad/tvm/src/meta_schedule/schedule_rule/apply_custom_rule.cc:59: Warning: Unknown schedule rule \"meta_schedule.adaptive_pool_avg\" for target keys \"[\"arm_cpu\", \"cpu\"]\". Checked ffi::Functions:\n",
      "  meta_schedule.arm_cpu.meta_schedule.adaptive_pool_avg\n",
      "  meta_schedule.cpu.meta_schedule.adaptive_pool_avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #12: \"fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #13: \"transpose\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #14: \"fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #15: \"fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #16: \"fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #17: \"fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #18: \"fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:167] Initializing Task #19: \"max_pool2d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:59:18] /Users/hafsahshahzad/tvm/src/meta_schedule/schedule_rule/apply_custom_rule.cc:59: Warning: Unknown schedule rule \"meta_schedule.pool_max\" for target keys \"[\"arm_cpu\", \"cpu\"]\". Checked ffi::Functions:\n",
      "  meta_schedule.arm_cpu.meta_schedule.pool_max\n",
      "  meta_schedule.cpu.meta_schedule.pool_max\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1               N/A             N/A    \n",
       "1    231361536         2               N/A             N/A    \n",
       "2    115730944         1               N/A             N/A    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                      N/A         0           \n",
       "1                      N/A         0           \n",
       "2                      N/A         0           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 13:59:18 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:188] TaskScheduler picks Task #0: \"reshape\"\n",
      "2025-08-06 13:59:18 [INFO] [task_scheduler.cc:201] Sending 1 sample(s) to builder\n",
      "2025-08-06 13:59:19 [INFO] [task_scheduler.cc:203] Sending 1 sample(s) to runner\n",
      "2025-08-06 13:59:20 [INFO] [task_scheduler.cc:188] TaskScheduler picks Task #1: \"fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4\"\n",
      "2025-08-06 13:59:21 [INFO] [task_scheduler.cc:201] Sending 64 sample(s) to builder\n",
      "2025-08-06 13:59:25 [INFO] [task_scheduler.cc:203] Sending 64 sample(s) to runner\n",
      "2025-08-06 13:59:48 [INFO] [task_scheduler.cc:188] TaskScheduler picks Task #2: \"fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4\"\n",
      "2025-08-06 13:59:50 [INFO] [task_scheduler.cc:201] Sending 64 sample(s) to builder\n",
      "2025-08-06 13:59:52 [INFO] [task_scheduler.cc:203] Sending 64 sample(s) to runner\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter   0: tr-p-rmse: 0.450000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.450000\ttr-rmse: 0.450000\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.032305\ttr-a-peak@32: 1.000000\ttr-rmse: 0.032305\ttr-rmse: 0.032305\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.002319\ttr-a-peak@32: 1.000000\ttr-rmse: 0.002319\ttr-rmse: 0.002319\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  75: tr-p-rmse: 0.000166\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000166\ttr-rmse: 0.000166\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter 100: tr-p-rmse: 0.000012\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000012\ttr-rmse: 0.000012\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter 125: tr-p-rmse: 0.000001\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000001\ttr-rmse: 0.000001\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter 150: tr-p-rmse: 0.000000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000000\ttr-rmse: 0.000000\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter 175: tr-p-rmse: 0.000000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000000\ttr-rmse: 0.000000\n",
      "2025-08-06 14:00:20 [DEBUG] XGB stopped. Best iteration: [131] tr-p-rmse:0.00000\ttr-a-peak@32:1.00000\ttr-rmse:0.00000\ttr-rmse:0.00000 \n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:245] [Updated] Task #0: \"reshape\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2               N/A             N/A    \n",
       "2    115730944         1               N/A             N/A    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1           \n",
       "1                      N/A         0           \n",
       "2                      N/A         0           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |      \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 9.40678\n",
      "\n",
      "\n",
      "Total trials: 1\n",
      "Total latency (us): 9.40678\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #0 has finished. Remaining task(s): 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2               N/A             N/A    \n",
       "2    115730944         1               N/A             N/A    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                      N/A         0           \n",
       "2                      N/A         0           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 1\n",
      "Total latency (us): 9.40678\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 9.40678\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter   0: tr-p-rmse: 0.626978\ttr-a-peak@32: 0.972729\ttr-rmse: 0.315327\ttr-rmse: 0.315327\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.054593\ttr-a-peak@32: 1.000000\ttr-rmse: 0.349631\ttr-rmse: 0.349631\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.054569\ttr-a-peak@32: 1.000000\ttr-rmse: 0.349624\ttr-rmse: 0.349624\n",
      "2025-08-06 14:00:20 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.05430\ttr-a-peak@32:1.00000\ttr-rmse:0.34986\ttr-rmse:0.34986 \n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:245] [Updated] Task #1: \"fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1               N/A             N/A    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64           \n",
       "2                      N/A         0           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |      \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 65\n",
      "Total latency (us): 1420.42\n",
      "\n",
      "\n",
      "Total trials: 65\n",
      "Total latency (us): 1420.42\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #1 has finished. Remaining task(s): 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1               N/A             N/A    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                      N/A         0           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 65\n",
      "Total latency (us): 1420.42\n",
      "\n",
      "\n",
      "Total trials: 65\n",
      "Total latency (us): 1420.42\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter   0: tr-p-rmse: 0.594722\ttr-a-peak@32: 0.514313\ttr-rmse: 0.306794\ttr-rmse: 0.306794\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.044843\ttr-a-peak@32: 1.000000\ttr-rmse: 0.357912\ttr-rmse: 0.357912\n",
      "2025-08-06 14:00:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.044856\ttr-a-peak@32: 1.000000\ttr-rmse: 0.357898\ttr-rmse: 0.357898\n",
      "2025-08-06 14:00:20 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.04479\ttr-a-peak@32:1.00000\ttr-rmse:0.35797\ttr-rmse:0.35797 \n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:245] [Updated] Task #2: \"fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64           \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |      \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #2 has finished. Remaining task(s): 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0           \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #3 has finished. Remaining task(s): 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0           \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #4 has finished. Remaining task(s): 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0           \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #5 has finished. Remaining task(s): 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0           \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #6 has finished. Remaining task(s): 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0           \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #7 has finished. Remaining task(s): 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0           \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #8 has finished. Remaining task(s): 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0           \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #9 has finished. Remaining task(s): 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0           \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #10 has finished. Remaining task(s): 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0           \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #11 has finished. Remaining task(s): 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0           \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #12 has finished. Remaining task(s): 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0           \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #13 has finished. Remaining task(s): 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0           \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #14 has finished. Remaining task(s): 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0           \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #15 has finished. Remaining task(s): 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0       Y   \n",
       "16                     N/A         0           \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #16 has finished. Remaining task(s): 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0       Y   \n",
       "16                     N/A         0       Y   \n",
       "17                     N/A         0           \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #17 has finished. Remaining task(s): 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0       Y   \n",
       "16                     N/A         0       Y   \n",
       "17                     N/A         0       Y   \n",
       "18                     N/A         0           \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |      \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #18 has finished. Remaining task(s): 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0       Y   \n",
       "16                     N/A         0       Y   \n",
       "17                     N/A         0       Y   \n",
       "18                     N/A         0       Y   \n",
       "19                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [INFO] [task_scheduler.cc:268] Task #19 has finished. Remaining task(s): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reshape</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>9.4068</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4</td>\n",
       "      <td>231361536</td>\n",
       "      <td>2</td>\n",
       "      <td>327.9360</td>\n",
       "      <td>705.5082</td>\n",
       "      <td>1411.0164</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>115730944</td>\n",
       "      <td>1</td>\n",
       "      <td>174.3689</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>663.7133</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fused_matmul_add13</td>\n",
       "      <td>1025000</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive_avg_pool2d</td>\n",
       "      <td>25600</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>231461888</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5</td>\n",
       "      <td>13246464</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>231712768</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4</td>\n",
       "      <td>231336448</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8</td>\n",
       "      <td>13045760</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3</td>\n",
       "      <td>115856384</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2</td>\n",
       "      <td>231813120</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1</td>\n",
       "      <td>232415232</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transpose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2</td>\n",
       "      <td>116107264</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1</td>\n",
       "      <td>232214528</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu</td>\n",
       "      <td>240041984</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11</td>\n",
       "      <td>12945408</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3</td>\n",
       "      <td>231512064</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>max_pool2d</td>\n",
       "      <td>1806336</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Name   \\\n",
       "0                                                                                  reshape    \n",
       "1    fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4    \n",
       "2          fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "3                                                                       fused_matmul_add13    \n",
       "4                                                                      adaptive_avg_pool2d    \n",
       "5           fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "6                 fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5    \n",
       "7           fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "8          fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4    \n",
       "9                 fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8    \n",
       "10          fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3    \n",
       "11     fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2    \n",
       "12       fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1    \n",
       "13                                                                               transpose    \n",
       "14          fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2    \n",
       "15            fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1    \n",
       "16                 fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu    \n",
       "17              fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11    \n",
       "18     fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3    \n",
       "19                                                                              max_pool2d    \n",
       "\n",
       "          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0            1         1            0.0001          9.4068    \n",
       "1    231361536         2          327.9360        705.5082    \n",
       "2    115730944         1          174.3689        663.7133    \n",
       "3      1025000         1               N/A             N/A    \n",
       "4        25600         1               N/A             N/A    \n",
       "5    231461888         1               N/A             N/A    \n",
       "6     13246464         1               N/A             N/A    \n",
       "7    231712768         1               N/A             N/A    \n",
       "8    231336448         1               N/A             N/A    \n",
       "9     13045760         1               N/A             N/A    \n",
       "10   115856384         1               N/A             N/A    \n",
       "11   231813120         2               N/A             N/A    \n",
       "12   232415232         2               N/A             N/A    \n",
       "13           1         1               N/A             N/A    \n",
       "14   116107264         1               N/A             N/A    \n",
       "15   232214528         2               N/A             N/A    \n",
       "16   240041984         1               N/A             N/A    \n",
       "17    12945408         1               N/A             N/A    \n",
       "18   231512064         2               N/A             N/A    \n",
       "19     1806336         1               N/A             N/A    \n",
       "\n",
       "     Weighted Latency (us)    Trials    Done   \n",
       "0                   9.4068         1       Y   \n",
       "1                1411.0164        64       Y   \n",
       "2                 663.7133        64       Y   \n",
       "3                      N/A         0       Y   \n",
       "4                      N/A         0       Y   \n",
       "5                      N/A         0       Y   \n",
       "6                      N/A         0       Y   \n",
       "7                      N/A         0       Y   \n",
       "8                      N/A         0       Y   \n",
       "9                      N/A         0       Y   \n",
       "10                     N/A         0       Y   \n",
       "11                     N/A         0       Y   \n",
       "12                     N/A         0       Y   \n",
       "13                     N/A         0       Y   \n",
       "14                     N/A         0       Y   \n",
       "15                     N/A         0       Y   \n",
       "16                     N/A         0       Y   \n",
       "17                     N/A         0       Y   \n",
       "18                     N/A         0       Y   \n",
       "19                     N/A         0       Y   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n",
      "2025-08-06 14:00:20 [DEBUG] [task_scheduler.cc:326] \n",
      " ID |                                                                                  Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 |                                                                               reshape |         1 |      1 |         0.0001 |       9.4068 |                9.4068 |      1 |    Y \n",
      "  1 | fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4 | 231361536 |      2 |       327.9360 |     705.5082 |             1411.0164 |     64 |    Y \n",
      "  2 |       fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 115730944 |      1 |       174.3689 |     663.7133 |              663.7133 |     64 |    Y \n",
      "  3 |                                                                    fused_matmul_add13 |   1025000 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  4 |                                                                   adaptive_avg_pool2d |     25600 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  5 |        fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 231461888 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  6 |              fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5 |  13246464 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  7 |        fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 231712768 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  8 |       fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4 | 231336448 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "  9 |              fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8 |  13045760 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 10 |        fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3 | 115856384 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 11 |   fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2 | 231813120 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 12 |     fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1 | 232415232 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 13 |                                                                             transpose |         1 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 14 |        fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2 | 116107264 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 15 |          fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1 | 232214528 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 16 |               fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu | 240041984 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 17 |            fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11 |  12945408 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 18 |   fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3 | 231512064 |      2 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      " 19 |                                                                            max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |    Y \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 129\n",
      "Total latency (us): 2084.14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:00:20] /Users/hafsahshahzad/tvm/src/relax/transform/meta_schedule.cc:90: Warning: Creating JSONDatabase. Workload at: tuning_logs/database_workload.json, Tuning records at: tuning_logs/database_tuning_record.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #A2F\">@R</span><span style=\"color: #A2F; font-weight: bold\">.</span>function\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">main</span>(x: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer1___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer2___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer3___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_0_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___0___downsample_1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_getattr_l__self___layer4___1___bn2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_fc_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1000</span>, <span style=\"color: #008000\">512</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), p_fc_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1000</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">-&gt;</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "    R<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>dataflow():\n",
       "        lv <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d_subtract_divide_expand_dims_multiply_expand_dims_add1_relu, (x, p_conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>], p_bn1_weight, p_bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">112</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv4 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(max_pool2d, (lv,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv1 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1, (lv4, p_getattr_l__self___layer1___0___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>], p_getattr_l__self___layer1___0___bn1_weight, p_getattr_l__self___layer1___0___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv2 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1, (lv1, p_getattr_l__self___layer1___0___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">4</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">5</span>], p_getattr_l__self___layer1___0___bn2_weight, p_getattr_l__self___layer1___0___bn2_bias, lv4), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv3 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_relu1, (lv2, p_getattr_l__self___layer1___1___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">6</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">7</span>], p_getattr_l__self___layer1___1___bn1_weight, p_getattr_l__self___layer1___1___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv4_1 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d1_subtract1_divide1_expand_dims_multiply1_expand_dims_add2_add3_relu1, (lv3, p_getattr_l__self___layer1___1___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">8</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">9</span>], p_getattr_l__self___layer1___1___bn2_weight, p_getattr_l__self___layer1___1___bn2_bias, lv2), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv5 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d2_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2, (lv4_1, p_getattr_l__self___layer2___0___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">10</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">11</span>], p_getattr_l__self___layer2___0___bn1_weight, p_getattr_l__self___layer2___0___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv6 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d4_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5, (lv4_1, p_getattr_l__self___layer2___0___downsample_0_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">12</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">13</span>], p_getattr_l__self___layer2___0___downsample_1_weight, p_getattr_l__self___layer2___0___downsample_1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv7 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2, (lv5, p_getattr_l__self___layer2___0___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">14</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">15</span>], p_getattr_l__self___layer2___0___bn2_weight, p_getattr_l__self___layer2___0___bn2_bias, lv6), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv8 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_relu2, (lv7, p_getattr_l__self___layer2___1___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">16</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">17</span>], p_getattr_l__self___layer2___1___bn1_weight, p_getattr_l__self___layer2___1___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv9 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d3_subtract2_divide2_expand_dims1_multiply2_expand_dims1_add5_add6_relu2, (lv8, p_getattr_l__self___layer2___1___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">18</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">19</span>], p_getattr_l__self___layer2___1___bn2_weight, p_getattr_l__self___layer2___1___bn2_bias, lv7), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv10 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d5_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3, (lv9, p_getattr_l__self___layer3___0___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">20</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">21</span>], p_getattr_l__self___layer3___0___bn1_weight, p_getattr_l__self___layer3___0___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv11 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d7_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8, (lv9, p_getattr_l__self___layer3___0___downsample_0_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">22</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">23</span>], p_getattr_l__self___layer3___0___downsample_1_weight, p_getattr_l__self___layer3___0___downsample_1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv12 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3, (lv10, p_getattr_l__self___layer3___0___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">24</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">25</span>], p_getattr_l__self___layer3___0___bn2_weight, p_getattr_l__self___layer3___0___bn2_bias, lv11), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv13 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_relu3, (lv12, p_getattr_l__self___layer3___1___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">26</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">27</span>], p_getattr_l__self___layer3___1___bn1_weight, p_getattr_l__self___layer3___1___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv14 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d6_subtract3_divide3_expand_dims2_multiply3_expand_dims2_add8_add9_relu3, (lv13, p_getattr_l__self___layer3___1___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">28</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">29</span>], p_getattr_l__self___layer3___1___bn2_weight, p_getattr_l__self___layer3___1___bn2_bias, lv12), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv15 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d8_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4, (lv14, p_getattr_l__self___layer4___0___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">30</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">31</span>], p_getattr_l__self___layer4___0___bn1_weight, p_getattr_l__self___layer4___0___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv16 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d10_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11, (lv14, p_getattr_l__self___layer4___0___downsample_0_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">32</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">33</span>], p_getattr_l__self___layer4___0___downsample_1_weight, p_getattr_l__self___layer4___0___downsample_1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv17 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4, (lv15, p_getattr_l__self___layer4___0___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">34</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">35</span>], p_getattr_l__self___layer4___0___bn2_weight, p_getattr_l__self___layer4___0___bn2_bias, lv16), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv18 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_relu4, (lv17, p_getattr_l__self___layer4___1___conv1_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">36</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">37</span>], p_getattr_l__self___layer4___1___bn1_weight, p_getattr_l__self___layer4___1___bn1_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv19 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_conv2d9_subtract4_divide4_expand_dims3_multiply4_expand_dims3_add11_add12_relu4, (lv18, p_getattr_l__self___layer4___1___conv2_weight, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">38</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">39</span>], p_getattr_l__self___layer4___1___bn2_weight, p_getattr_l__self___layer4___1___bn2_bias, lv17), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">7</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv86 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(adaptive_avg_pool2d, (lv19,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv87 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(reshape, (lv86,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">512</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv88 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(transpose, (p_fc_weight,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">512</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        lv20 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(fused_matmul_add13, (lv87, lv88, p_fc_bias), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "        gv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tuple(R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1000</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">=</span> (lv20,)\n",
       "        R<span style=\"color: #A2F; font-weight: bold\">.</span>output(gv)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "TOTAL_TRIALS = 100  # You can increase to 20000 for better tuning quality\n",
    "target = tvm.target.Target(\"llvm -num-cores=4\")  # Use 'llvm' for Apple macOS CPU\n",
    "work_dir = \"tuning_logs\"\n",
    "\n",
    "\n",
    "# Run tuning pipeline unless in CI environment\n",
    "if not IS_IN_CI:\n",
    "    mod_optimized = relax.get_pipeline(\"static_shape_tuning\", target=target, total_trials=TOTAL_TRIALS)(mod)\n",
    "    mod_optimized[\"main\"].show()\n",
    "else:\n",
    "    mod_optimized = mod  # fallback if skipping tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a45067a-a00b-49d4-aa81-976cdf15395b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "<class 'tvm.ir.module.IRModule'> has no attribute state_dict",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mtvm/ffi/cython/object.pxi:128\u001b[39m, in \u001b[36mtvm.ffi.core.Object.__getattr__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mtvm/ffi/cython/function.pxi:247\u001b[39m, in \u001b[36mtvm.ffi.core.Function.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tvm/src/node/reflection.cc:70\u001b[39m, in \u001b[36mvoid tvm::NodeGetAttr(ffi::PackedArgs, ffi::Any *)\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m if (!success) {\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m   TVM_FFI_THROW(AttributeError) << self->GetTypeKey() << \" object has no attribute `\"\n\u001b[32m     71\u001b[39m                                 << field_name << \"`\";\n",
      "\u001b[31mAttributeError\u001b[39m: ir.IRModule object has no attribute `state_dict`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     avg_ms = (\u001b[38;5;28msum\u001b[39m(times) / n_repeat) * \u001b[32m1000\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_ms\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m state_dict_mod = \u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m()\n\u001b[32m     31\u001b[39m params_mod = {k: tvm.nd.array(v.cpu().numpy()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict_mod.items()}\n\u001b[32m     32\u001b[39m state_dict_modOpt = mod_optimized.state_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mtvm/ffi/cython/object.pxi:130\u001b[39m, in \u001b[36mtvm.ffi.core.Object.__getattr__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: <class 'tvm.ir.module.IRModule'> has no attribute state_dict"
     ]
    }
   ],
   "source": [
    "# Convert example input tensor to TVM NDArray\n",
    "input_data = [tvm.nd.array(example_args[0].numpy())]\n",
    "target = tvm.target.Target(\"llvm -num-cores=4\")\n",
    "# 🛠️ Convert model weights to TVM NDArrays\n",
    "\n",
    "# Helper function to build, run, and measure average inference time (ms)\n",
    "#module[\"main\"].params is a list of all 63 parameters. The first is the input (x). The rest (62) are detached model weights (p_fc_weight, p_conv1_weight, etc.). You must pass all 63 in order when calling the VM\n",
    "def run_and_time(module, input_data,params, target, n_repeat=10):\n",
    "    ex = relax.build(module, target=target, params=params)\n",
    "    vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "     # Gather full list of arguments: [input] + [params in order]\n",
    "    full_args = [*input_data]\n",
    "    for param in module[\"main\"].params[1:]:  # skip input[0], add weights\n",
    "        full_args.append(params[param.name_hint])\n",
    "        \n",
    "    # Warmup\n",
    "    vm[\"main\"](*full_args)\n",
    "\n",
    "    times = []\n",
    "    for _ in range(n_repeat):\n",
    "        start = time.time()\n",
    "        vm[\"main\"](*full_args)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_ms = (sum(times) / n_repeat) * 1000\n",
    "    return avg_ms\n",
    "\n",
    "state_dict_mod = mod.state_dict()\n",
    "params_mod = {k: tvm.nd.array(v.cpu().numpy()) for k, v in state_dict_mod.items()}\n",
    "state_dict_modOpt = mod_optimized.state_dict()\n",
    "params_modOpt = {k: tvm.nd.array(v.cpu().numpy()) for k, v in state_dict_modOpt.items()}\n",
    "# Measure before tuning\n",
    "time_before = run_and_time(mod, input_data,params_mod, target)\n",
    "# Measure after tuning\n",
    "time_after = run_and_time(mod_optimized, input_data,params_modOpt, target)\n",
    "\n",
    "print(f\"Average inference time before tuning: {time_before:.2f} ms\")\n",
    "print(f\"Average inference time after tuning: {time_after:.2f} ms\")\n",
    "\n",
    "# Visualization\n",
    "plt.bar([\"Before Tuning\", \"After Tuning\"], [time_before, time_after], color=[\"red\", \"green\"])\n",
    "plt.ylabel(\"Average Inference Time (ms)\")\n",
    "plt.title(\"ResNet18 Inference Performance Before vs After TVM Tuning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace2738-4728-4f31-867a-83810f77dc37",
   "metadata": {},
   "source": [
    "#https://tvm.apache.org/docs/v0.13.0/tutorial/tvmc_command_line_driver.html\n",
    "\n",
    "For this tutorial, we will be working with ResNet-50 v2. ResNet-50 is a convolutional neural \n",
    "network that is 50 layers deep and designed to classify images. The model we will be using \n",
    "has been pre-trained on more than a million images with 1000 different classifications. \n",
    "The network has an input image size of 224x224. If you are interested exploring more of how \n",
    "the ResNet-50 model is structured, we recommend downloading Netron, a freely available\n",
    "ML model viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0289e03-e0e8-439f-92fe-4effdc62df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 97.6M  100 97.6M    0     0  4098k      0  0:00:24  0:00:24 --:--:-- 4678k\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# The exclamation mark (!) tells Jupyter to run the line as a shell command, not Python.\n",
    "\n",
    "!curl -L -o resnet50-v2-7.onnx https://github.com/onnx/models/raw/b9a54e89508f101a1611cd64f4ef56b9cb62c7cf/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
    "import os\n",
    "print(os.path.exists(\"resnet50-v2-7.onnx\"))  # should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c447e3fd-463f-429f-a368-45ae701f8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: tvmc\n"
     ]
    }
   ],
   "source": [
    "# This may take several minutes depending on your machine\n",
    "!tvmc compile --target \"llvm\" \\\n",
    "--input-shapes \"data:[1,3,224,224]\" \\\n",
    "--output resnet50-v2-7-tvm.tar \\\n",
    "resnet50-v2-7.onnx\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
